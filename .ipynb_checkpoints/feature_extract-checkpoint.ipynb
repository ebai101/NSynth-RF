{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Volumes/FilesHDD/CODE/mmai-proj/nsynth-train/audio/'\n",
    "sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw\n",
    "df_train_raw = pd.read_json (path_or_buf='nsynth-train/examples.json', orient='index')\n",
    "\n",
    "# Sample n files\n",
    "df_train_sample = df_train_raw.groupby('instrument_family', as_index=False, #group by instrument family\n",
    "                               group_keys=False).apply(lambda df: df.sample(sample_size)) #number of samples\n",
    "# drop the synth_lead from the training dataset\n",
    "df_train_sample = df_train_sample[df_train_sample['instrument_family']!=9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle filenames\n",
    "filenames_train = df_train_sample.index.tolist()\n",
    "with open('filenames_train.pickle', 'wb') as f:\n",
    "    pickle.dump(filenames_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(file):\n",
    "    \"\"\"\n",
    "    Define function that takes in a file an returns features in an array\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Extracting features for {}\".format (file[len(train_dir):]))\n",
    "    \n",
    "    #get wave representation\n",
    "    y, sr = librosa.load(file)\n",
    "        \n",
    "    #determine if instruemnt is harmonic or percussive by comparing means\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    if np.mean(y_harmonic)>np.mean(y_percussive):\n",
    "        harmonic=1\n",
    "    else:\n",
    "        harmonic=0\n",
    "        \n",
    "    #Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    #temporal averaging\n",
    "    mfcc=np.mean(mfcc,axis=1)\n",
    "    \n",
    "    #get the mel-scaled spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)  \n",
    "    #temporally average spectrogram\n",
    "    spectrogram = np.mean(spectrogram, axis = 1)\n",
    "    \n",
    "    #compute chroma energy\n",
    "    chroma = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    #temporally average chroma\n",
    "    chroma = np.mean(chroma, axis = 1)\n",
    "    \n",
    "    #compute spectral contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    contrast = np.mean(contrast, axis= 1)\n",
    "    \n",
    "    return [harmonic, mfcc, spectrogram, chroma, contrast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instrument_code(filename):\n",
    "    class_names=['bass', 'brass', 'flute', 'guitar', \n",
    "             'keyboard', 'mallet', 'organ', 'reed', \n",
    "             'string', 'synth_lead', 'vocal']\n",
    "    \n",
    "    for name in class_names:\n",
    "        if name in filename:\n",
    "            return class_names.index(name)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to extract 50 files is 23.390511989593506 seconds\n"
     ]
    }
   ],
   "source": [
    "start_train = time.time()\n",
    "\n",
    "#create dictionary to store all test features\n",
    "dict_train = {}\n",
    "#loop over every file in the list\n",
    "for file in filenames_train:\n",
    "    #extract the features\n",
    "    features = feature_extract(train_dir+ file + '.wav') #specify directory and .wav\n",
    "    #add dictionary entry\n",
    "    dict_train[file] = features\n",
    "\n",
    "end_train=time.time()\n",
    "print('Time to extract {} files is {} seconds'.format(len(filenames_train), end_train - start_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to dataframe\n"
     ]
    }
   ],
   "source": [
    "print('Converting to dataframe')\n",
    "\n",
    "#convert dict to dataframe\n",
    "features_train = pd.DataFrame.from_dict(dict_train, orient='index',\n",
    "                                       columns=['harmonic', 'mfcc', 'spectro', 'chroma', 'contrast'])\n",
    "\n",
    "#extract mfccs\n",
    "mfcc_train = pd.DataFrame(features_train.mfcc.values.tolist(),\n",
    "                          index=features_train.index)\n",
    "mfcc_train = mfcc_train.add_prefix('mfcc_')\n",
    "\n",
    "#extract spectro\n",
    "spectro_train = pd.DataFrame(features_train.spectro.values.tolist(),\n",
    "                             index=features_train.index)\n",
    "spectro_train = spectro_train.add_prefix('spectro_')\n",
    "\n",
    "\n",
    "#extract chroma\n",
    "chroma_train = pd.DataFrame(features_train.chroma.values.tolist(),\n",
    "                            index=features_train.index)\n",
    "chroma_train = chroma_train.add_prefix('chroma_')\n",
    "\n",
    "\n",
    "#extract contrast\n",
    "contrast_train = pd.DataFrame(features_train.contrast.values.tolist(),\n",
    "                              index=features_train.index)\n",
    "contrast_train = chroma_train.add_prefix('contrast_')\n",
    "\n",
    "#drop the old columns\n",
    "features_train = features_train.drop(labels=['mfcc', 'spectro', 'chroma', 'contrast'], axis=1)\n",
    "\n",
    "#concatenate\n",
    "df_features_train=pd.concat([features_train, mfcc_train, spectro_train, chroma_train, contrast_train],\n",
    "                           axis=1, join='inner')\n",
    "\n",
    "targets_train = []\n",
    "for name in df_features_train.index.tolist():\n",
    "    targets_train.append(instrument_code(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Writing to df_features.pickle')\n",
    "df_features_train['targets'] = targets_train\n",
    "with open('df_features.pickle', 'wb') as f:\n",
    "    pickle.dump(df_features_train, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
